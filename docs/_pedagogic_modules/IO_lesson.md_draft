



### Learning Objectives

- Understand the concept of IO
- Understand the impact of IO operations on computing
- Understand the basics of optimizing computation around IO operations


### Basic Concepts

In computing, the processor typicallt does not run program start to finish in a vacuum. Programs often 
need to consume **I**nput and produce **O**utput, referred to as **IO operations**. A couple of very common IO operations are reading from 
disk and writing to disk. As the disk is much slower than the CPU, even small disk reads or writes can represent a large (from the CPU's perspective) chunk of time during which the CPU is sitting idle. 

When it comes to IO operations, not all programs are created equal. Some programs will require more IO time than others. In fact, programs are typically categorized as IO- or CPU-intensive. If a program spends more time performing IO operations than CPU operations, it is said to be *IO-intensive*. If the situation is reversed, the program is said to be *CPU-intensive*. For instance, a program that reads a large jpg image from disk, reduces the brightness of every pixel  (to make the image darker), and writes the modified image to disk is IO-intensive on most standard computers (a lot of data to read/write from/to disk, and very quick computation on this data - in this case perhaps just a simple subtraction). By contrast, a program that instead of reducing the brightness of the image applies an oil painting filter to it will
most likely be CPU-intensive (applying an oil painting filter entails many, many more computations than a simple subtraction). 

As mentioned above, reading from and writing to the disk are slow operations compared to the CPU. Typically, there is a difference between read and write speeds as well. Reading is 
typically significantly faster than writing. Furthermore, different kinds of disks have different speeds as well. The table below shows advertiesed
read and write speeds for two mass-market SATA disks, a Hard Disk Drive (HDD) and a Solid  State Drive (SSD): 


| Disk            | Read bandwidth | Write bandwidth |
|-----------------|----------------|-----------------|
| WD HDD (10EZEX) | 160 MB/sec     | 143 MB/sec      |
| Samsung 860 EVO | 550 MB/sec     | 520 MB/sec      |


The read and write speeds are often referred to as *bandwidths*. The units above is MB/sec (MegaByte  per second), which is also written as MBps. 

Determining the exact bandwidth that disk reads and writes will experience during program execution is actually difficult (due to the complexity of the underlying hardware and software, and due to how the data is stored and accessed on the disk).  In this module we will akways that disk bandwidths are constant.

### A program with computation and IO

Let us consider a program that performs a task in three phases. First, it reads data from disk. Second, it performs some computation on that data to create new data. And third, it writes the new data back to disk.  This
could be one of the image processing programs mentioned in the previous section as examples.  If this program is invoked to process 2 images, i.e., so that it performs 2 tasks, then its execution timeline is as depicted below:

<object class="figure" type="image/svg+xml" data="{{ site.baseurl }}/public/img/io_effects/IO_figure_1.svg">Figure 1: Example execution timeline</object>

As can be seen in the figure, at any given time either the CPU is idle (while IO operations are ongoing) or the disk is idle (while computation is ongoing). In the above figure, reading an image from disk takes 1 second, writing an image to disk takes 1 second, and processing an image takes 2 seconds. (We can thus infer that the two images have the same size, and that the disk has identical read and write bandwidths).  We can compute the CPU Utilization as follows:

$$
\begin{align}

  \text{CPU Utilization} & = \frac{T_{Compute}}{T_{Compute} + T_{Idle}} \\
                         & = \frac{4}{4 + 4} \\
                         & = 0.5

\end{align}
$$

This means that the CPU is idle for half of the execution of the program. This program is perfectly balanced, i.e., it is neither CPU-intensive nor IO-intensive. 

### Overlaping computation and IO

The execution in the previous section can be improved. This is because the CPU and the disk are two different pieces of hardware, and they can work at the same time. As a result, while the CPU is processing the 1st image, the 2nd image could be read from disk! The CPU can then start processing the 2nd image right away after it finishes processing the 1st image. The 1st image can be written to disk at the same time. This execution is depicted below:


<object class="figure" type="image/svg+xml" data="{{ site.baseurl }}/public/img/io_effects/IO_figure_2.svg">Figure 2: Example execution timeline with overlap of IO and computation</object>

The total execution time has dropped by 2 seconds **and** the CPU utilization is increased:

$$
\begin{align}

  \text{CPU Utilization} & = \frac{T_{Compute}}{T_{Compute} + T_{Idle}} \\
                         & = \frac{4}{4 + 2} \\
                         & = 0.66
                         
\end{align}
$$

If there were additional, similar images to process, the CPU utilization would continue to drop as it would be idle only at the very beginning and at the very end of the execution. 

The above is an ideal situation because IO time for an image is exactly equal to compute time. If, for isntance, the time to read an image is now 2s (for instance because the program reads bigger images but writes back downscaled images) and the program must process 3 images, then the execution would be as:

<object class="figure" type="image/svg+xml" data="{{ site.baseurl }}/public/img/io_effects/IO_figure_3.svg">Figure 3: Example execution timeline with overlap of IO and computation</object>

In this case, the CPU does experience idle time because images cannot be read from disk fast enough.  So although overlaping IO and computation almost always reduces program execution time, the benefit can vary based on IO and computation volumes (and especially if these volumes vary from task to task). 



<!--#### CPU-intensive vs. IO-intensive executions

Let us return to the first example execution above: 

<object class="figure" type="image/svg+xml" data="{{ site.baseurl }}/public/img/io_effects/IO_figure_1.svg">Execution timeline</object>


In this case, we can string together as many tasks as we want and the CPU will be utilized continuously apart from
the initial read and the final write. With two tasks the IO time is a significant portion of the execution time,
but if we were to have, say, 1000 tasks to complete, that initial read and last write are a negligible portion of the
overall execution time. So, *even though the program technically spends twice as much time doing IO than computing*, because of overlap of the operation the program

 This is what we can refer to as *CPU Driven* execution time and will occur when read and write 
times are sufficiently short for tasks compared with CPU computation time needed. 

As you may guess, the other side of the coin is *IO Driven* execution times where a task's time spent on IO is longer than the 
CPU time needed. In these cases, CPU utilization will be lower due to the need to wait on IO operations to complete. -->


### Putting it all this in practice

In practice, one can implement a program that overlaps IO and computation. This can be done by using non-blocking IO operations and/or threads. These are techniques that are often taught in Operating Systems courses. The overlap may not be completely "free", as reading/writing data from disk can still requires the CPU to perform some computation. Therefore, there can be time-sharing of the CPU between the IO operations and the computation, and the computation  is slowed down a little bit by the IO operations (something we did not show in the figures above). This said, there are ways for IO operations use almost no CPU cycles. One such technique, which relies on specific but commonplace hardware, is called Direct Memory Access (DMA). See an Operating Systems course for more details.

Another practical concern is RAM pressure. When going from the example execution in Figure 1 to that in Figure 2, the peak amount of RAM needed by the program is increased because at some point more than one input images are held in RAM. As previous modules have touched on, tasks can have significant memory
requirements, and it may not be possible to overlap IO and computation due to RAM space constraints.  

### Simulating IO

So that you can gain hands-on experience with the above concepts, use the simulation Web application
(see <a href="{{site.baseurl}}/pedagogic_modules/simulation_instructions/index/" target="_blank">instructions</a>), selecting `IO Operations` from its menu.


Initially, you can create a series of identical tasks that have a certain input and output. Run the simulation to see
the progression of tasks and host utilization without allowing IO to overlap with computation. Once you have observed
this, try selecting the checkbox to allow overlap.

With IO overlap there should be an improvement in execution time and host utilization. You can view this in the output
graphs that are generated. You can also try varying the input/output and computation amounts to create IO intensive or CPU
intensive tasks. Understanding which tasks will benefit from increased R/W or computation speeds will assist you in answering the questions to come.


### Practice Questions

For the purposes of these questions you are working at a company that runs instances of the same task repeatedly. On the currently available hardware, the time to process a task instance is as follows:

  - Read input: 2 Seconds  
  - CPU computation: 2 Seconds  
  - Write output: 2 Seconds  


**[I.p1.1]** For the same price, you may upgrade your CPU so that it can perform the computation for each task in 1 second, or you may 
upgrade to a SSD from your current HDD which will halve Read/Write times to 1 second each. Which would improve your 
execution time the most for executing one task instance?

<div class="ui accordion fluid">
  <div class="title">
    <i class="dropdown icon"></i>
    (click to see answer)
  </div>
  <div markdown="1" class="ui segment content">
   Looking at the time breakdown it is clear that task instances are IO-intensive.  In this case it will not help to decrease CPU computation time, so we should instead upgrade our HDD to a SSD. 
    This will decrease the task execution time from 6 seconds to 4 seconds.  After the upgrade, the task execution is now CPU-intensive. 

  </div>
</div>

**[I.p1.2]** It is decided to purchase the SSD to replace the HDD currently being used, which decreases read/write times to 1 
second each. The program that executes the task was designed to overlap IO and computation when executing multiple task instances in sequence: while computing for task *i* it reads the input of task *i+1*, and while writing the output of task *i* it can compute for task *i+1*. What is the improvement seen 
from this change in terms of CPU utilization when running 5 task instances consecutively?

<div class="ui accordion fluid">
  <div class="title">
    <i class="dropdown icon"></i>
    (click to see answer)
  </div>
  <div markdown="1" class="ui segment content">
  Initially, read/write times were 2 seconds each, adding up to 4 seconds, while the CPU time was 2 seconds, for each task  instance. The total execution time for five tasks will be 22 seconds, of which 15 seconds of that is CPU time. This leads to a CPU utilization of 15/22 = 0.68. 
    
  When read/write times are decreased to 1 second each, now the full execution time will be just 17 seconds. The CPU 
    time does not change, remaining 15 seconds. This improves our CPU utilization to 15/17 = 0.88.

  </div>
</div>
 

### Questions

**[I.q1.1]**

A task that is run thousands of times a day requires 50 MB of input data to be loaded from disk before computation and
writes 50 MB of data to disk once computation has been completed. The disk itself is capable of read and write speeds of
100 MBps. The computation required for each task is 500 GFlop and the processor can do 250 GFlops.

Ignoring the initial read and final write in your calculations, if we want to decrease the time per task, should we focus on upgrading the
processor or acquiring faster memory?

**[I.q2.1]**

A task requires 100 MB of input data to be loaded from disk and 1 TFlop of computation. It is being run in batches of
fifty consecutive identical tasks on a computer with a processor capable of 250 Gflops and a disk with R/W speeds of
100 MBps.

How large can the output that must be written to disk be without impacting processor utilization (ignore the initial read
and final write in your calculations)?

**[I.q3.1]**

Consider a series of 10 identical tasks. With the hardware we have available, each task requires 1 second to read data
from disk, 1 second for computation, and 0.5 seconds to write the output back to the disk.

What is the execution time if we are not able to perform IO during computation? What is execution time when overlap of
computation and IO is possible?